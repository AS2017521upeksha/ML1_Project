{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ml project data scraping part from imdb site",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AS2017521upeksha/ML1_Project/blob/main/data_scraping_part_from_imdb_site.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M06IJ1UYfBnn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN9UBt1crfiv"
      },
      "source": [
        "from time import time\n",
        "from time import sleep\n",
        "from random import randint\n",
        "from IPython.core.display import clear_output\n",
        "from warnings import warn\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from requests import get\n",
        "\n",
        "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
        "\n",
        "fromyear = int(input(\"Enter From Year: \"))\n",
        "tillyear = int(input(\"Till Year: \"))\n",
        "\n",
        "\n",
        "# Redeclaring the lists to store data in\n",
        "names = []\n",
        "years = []\n",
        "imdb_ratings = []\n",
        "directors = []\n",
        "actors_1 = []\n",
        "actors_2 = []\n",
        "actors_3 = []\n",
        "actors_4 = []\n",
        "generes = []\n",
        "run_time = []\n",
        "writers = []\n",
        "producers = []\n",
        "countries = []\n",
        "sounds = []\n",
        "budget = []\n",
        "pages = [str(i) for i in range(1,5)]\n",
        "years_url = [str(i) for i in range(fromyear,tillyear)]\n",
        "\n",
        "# Preparing the monitoring of the loop\n",
        "start_time = time()\n",
        "requests = 0\n",
        "\n",
        "# For every year in the interval 2000-2017\n",
        "for year_url in years_url:\n",
        "\n",
        "    # For every page in the interval 1-4\n",
        "    for page in pages:\n",
        "\n",
        "        # Make a get request\n",
        "        response = get('http://www.imdb.com/search/title?release_date=' + year_url + \n",
        "        '&sort=num_votes,desc&page=' + page, headers = headers)\n",
        "\n",
        "        # Pause the loop\n",
        "        sleep(randint(8,15))\n",
        "\n",
        "        # Monitor the requests\n",
        "        requests += 1\n",
        "        elapsed_time = time() - start_time\n",
        "        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
        "        clear_output(wait = True)\n",
        "\n",
        "        # Throw a warning for non-200 status codes\n",
        "        if response.status_code != 200:\n",
        "            warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
        "\n",
        "        # Break the loop if the number of requests is greater than expected\n",
        "        if requests > 150:\n",
        "            warn('Number of requests was greater than expected.')  \n",
        "            break \n",
        "\n",
        "        # Parse the content of the request with BeautifulSoup\n",
        "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Select all the 50 movie containers from a single page\n",
        "        mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
        "\n",
        "        # For every movie of these 50\n",
        "        for container in mv_containers:\n",
        "            # If the movie has a Metascore, then:\n",
        "            if container.find('div', class_ = 'ratings-metascore') is not None:\n",
        "\n",
        "                # Scrape the name\n",
        "                name = container.h3.a.text\n",
        "                names.append(name)\n",
        "\n",
        "                # Scrape the year \n",
        "                year = container.h3.find('span', class_ = 'lister-item-year').text\n",
        "                year = year.replace(\"(\",\"\")\n",
        "                year = year.replace(\")\",\"\")\n",
        "                years.append(year)\n",
        "\n",
        "                # Scrape the IMDB rating\n",
        "                imdb = float(container.strong.text)\n",
        "                imdb_ratings.append(imdb)\n",
        "\n",
        "                #Scrape the director name\n",
        "                director_name = container.find_all(\"p\")[2].a.text\n",
        "                directors.append(director_name)\n",
        "\n",
        "                #scrape the 4 members of cast\n",
        "                c = container.find_all(\"p\")[2].find_all(\"a\")[1:5]\n",
        "                cast_1 = c[0].get_text()\n",
        "                cast_2 = c[1].get_text()\n",
        "                cast_3 = c[2].get_text()\n",
        "                cast_4 = c[3].get_text()\n",
        "                actors_1.append(cast_1)\n",
        "                actors_2.append(cast_2)\n",
        "                actors_3.append(cast_3)\n",
        "                actors_4.append(cast_4)\n",
        "                #scrape the gneres\n",
        "                genre = container.find_all(\"p\")[0].find(\"span\",class_=\"genre\").string.split(\",\")[0].strip()\n",
        "                generes.append(genre)\n",
        "                #scrape the run time\n",
        "                runtime = int(container.find_all(\"p\")[0].find(\"span\",class_=\"runtime\").string.split(\"min\")[0].strip())#split the min from data\n",
        "                run_time.append(runtime)\n",
        "\n",
        "                l = \"http://www.imdb.com/\"+container.h3.a['href'] #go to inside of movie page\n",
        "            \n",
        "                response_movie = get(l)\n",
        "\n",
        "                movie_html = BeautifulSoup(response_movie.text,'html.parser')\n",
        "\n",
        "                #scrape the the writer name\n",
        "                writer = movie_html.find_all(\"div\",class_=\"credit_summary_item\")[1].a.get_text().strip()\n",
        "                writers.append(writer)\n",
        "\n",
        "                text = movie_html.find_all(\"div\",id=\"titleDetails\")[0].get_text()\n",
        "                # remove whitespaces\n",
        "                text = re.sub(r\"\\s+\", \"\", text)\n",
        "\n",
        "                if len(re.findall(r\"ProductionCo:[A-Z,a-z]+\",text)) != 0:  #srape the production name by ProductionCo word because contain class is defferent from one to another\n",
        "                   productionco = re.findall(r\"ProductionCo:[A-Z,a-z]+\",text)[0]\n",
        "                   production = productionco.split(\":\")[1].split(\",\")[0]\n",
        "                else:\n",
        "                   production = \"NA\"\n",
        "                producers.append(production)\n",
        "\n",
        "                if len(re.findall(r\"Country:[A-Z,a-z]+\",text)) != 0:  #scrape the country\n",
        "                   country = re.findall(r\"Country:[A-Z,a-z]+\",text)[0]\n",
        "                   country = country.split(\":\")[1].split(\",\")[0]\n",
        "                else:\n",
        "                   country = \"NA\"\n",
        "                countries.append(country )\n",
        "\n",
        "                if len(re.findall(r\"SoundMix:[A-Z,a-z]+\",text)) != 0: #scrape the sound mix\n",
        "                   sound = re.findall(r\"SoundMix:[A-Z,a-z]+\",text)[0]\n",
        "                   sound = sound.split(\":\")[1].split(\",\")[0]\n",
        "                else:\n",
        "                   sound = \"NA\"\n",
        "                sounds.append(sound)\n",
        "\n",
        "                text = text.replace(\",\",\"\")\n",
        "                if len(re.findall(r\"Budget:\\$[0-9]+\",text)) != 0: #scrape the budget\n",
        "                   bt = re.findall(r\"Budget:\\$[0-9]+\",text)[0]\n",
        "                   bt = float(bt.split(\":\")[1].split(\"$\")[1])\n",
        "                else:\n",
        "                   bt = 0\n",
        "                \n",
        "                budget.append(bt)\n",
        "               \n",
        "\n",
        "movie_ratings = pd.DataFrame({'movie': names,\n",
        "                              'year': years,\n",
        "                              'imdb': imdb_ratings,\n",
        "                              'director_name' : directors,\n",
        "                              'actor_1_name' : actors_1,\n",
        "                              'actor_2_name' : actors_2,\n",
        "                              'actor_3_name' : actors_3,\n",
        "                              'actor_4_name' : actors_4,\n",
        "                              'gener' : generes,\n",
        "                              'run_time' : run_time,\n",
        "                              'writer' : writers,\n",
        "                              'production_house' : producers,\n",
        "                              'country' : countries,\n",
        "                              'sounds' : sounds,\n",
        "                              'budget' : budget})\n",
        "\n",
        "print(movie_ratings.info())\n",
        "movie_ratings.head(10)\n",
        "\n",
        "movie_ratings.to_csv('moviedata.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}